import type { ParsedData, ParsedColumn, ColumnType } from "./types"
import duckdb from "duckdb"
import path from "node:path"
import { createInflateRaw } from "node:zlib"
import { readFile } from "node:fs/promises"

/**
 * DuckDB-supported file types for this parser
 */
export type DuckDBFileType = "parquet" | "excel" | "arrow"

/**
 * Detect DuckDB file type from extension
 */
export function getDuckDBFileType(filePath: string): DuckDBFileType | null {
  const ext = path.extname(filePath).toLowerCase()
  switch (ext) {
    case ".parquet":
    case ".pq":
      return "parquet"
    case ".xlsx":
    case ".xls":
      return "excel"
    case ".arrow":
    case ".feather":
    case ".ipc":
      return "arrow"
    default:
      return null
  }
}

/**
 * Map DuckDB types to our column types
 */
function mapDuckDBType(duckdbType: string): ColumnType {
  const type = duckdbType?.toUpperCase() || ""

  // Integer types
  if (
    type.includes("INT") ||
    type.includes("BIGINT") ||
    type.includes("SMALLINT") ||
    type.includes("TINYINT") ||
    type.includes("HUGEINT")
  ) {
    return "number"
  }

  // Float types
  if (
    type.includes("FLOAT") ||
    type.includes("DOUBLE") ||
    type.includes("DECIMAL") ||
    type.includes("REAL")
  ) {
    return "number"
  }

  // Boolean
  if (type.includes("BOOL")) {
    return "boolean"
  }

  // Date/Time types
  if (
    type.includes("DATE") ||
    type.includes("TIME") ||
    type.includes("TIMESTAMP")
  ) {
    return "date"
  }

  // Default to string for everything else
  return "string"
}

/**
 * Process a row to handle BigInt and Date values for JSON serialization
 */
function processRow(row: Record<string, unknown>): Record<string, unknown> {
  const processed: Record<string, unknown> = {}
  for (const [key, value] of Object.entries(row)) {
    if (typeof value === "bigint") {
      processed[key] = Number(value)
    } else if (value instanceof Date) {
      processed[key] = value.toISOString()
    } else if (Buffer.isBuffer(value)) {
      processed[key] = value.toString("utf-8")
    } else {
      processed[key] = value
    }
  }
  return processed
}

/**
 * Execute a DuckDB query and return results as a promise
 */
function queryDuckDB(
  db: duckdb.Database,
  sql: string
): Promise<Record<string, unknown>[]> {
  return new Promise((resolve, reject) => {
    db.all(sql, (err, rows) => {
      if (err) {
        reject(err)
      } else {
        resolve(rows as Record<string, unknown>[])
      }
    })
  })
}

/**
 * Get the DuckDB read function for a file type
 */
function getReadFunction(
  fileType: DuckDBFileType,
  escapedPath: string,
  sheetName?: string
): string {
  switch (fileType) {
    case "parquet":
      return `read_parquet('${escapedPath}')`
    case "excel":
      // If a sheet name is provided, use it
      if (sheetName) {
        const escapedSheet = sheetName.replace(/'/g, "''")
        return `read_xlsx('${escapedPath}', sheet='${escapedSheet}')`
      }
      return `read_xlsx('${escapedPath}')`
    case "arrow":
      return `read_parquet('${escapedPath}')` // DuckDB uses read_parquet for Arrow IPC files too
    default:
      throw new Error(`Unsupported file type: ${fileType}`)
  }
}

/**
 * Install required DuckDB extensions for file type
 */
async function installExtensions(
  db: duckdb.Database,
  fileType: DuckDBFileType
): Promise<void> {
  if (fileType === "excel") {
    // DuckDB 1.2+ has native excel extension for xlsx files
    await queryDuckDB(db, "INSTALL excel")
    await queryDuckDB(db, "LOAD excel")
  }
}

export interface DuckDBParseOptions {
  limit?: number
  offset?: number
  sheetName?: string // For Excel files
}

/**
 * Parse a file using DuckDB and return structured data
 */
export async function parseDuckDBFile(
  filePath: string,
  options: DuckDBParseOptions = {}
): Promise<ParsedData> {
  const { limit = 1000, offset = 0, sheetName } = options

  const fileType = getDuckDBFileType(filePath)
  if (!fileType) {
    throw new Error(`Unsupported file type for DuckDB parser: ${filePath}`)
  }

  // Escape single quotes in file path for SQL
  const escapedPath = filePath.replace(/'/g, "''")
  const readFn = getReadFunction(fileType, escapedPath, sheetName)

  const db = new duckdb.Database(":memory:")

  try {
    // Install extensions if needed
    await installExtensions(db, fileType)

    // Get column info using DESCRIBE
    const describeResult = await queryDuckDB(
      db,
      `DESCRIBE SELECT * FROM ${readFn}`
    )

    const columns: ParsedColumn[] = describeResult.map((row) => ({
      name: String(row.column_name || row.name || ""),
      type: mapDuckDBType(String(row.column_type || row.type || "")),
    }))

    // Get total row count
    const countResult = await queryDuckDB(
      db,
      `SELECT COUNT(*) as cnt FROM ${readFn}`
    )
    const totalRows = Number(countResult[0]?.cnt || 0)

    // Get rows with pagination
    const dataResult = await queryDuckDB(
      db,
      `SELECT * FROM ${readFn} LIMIT ${limit} OFFSET ${offset}`
    )

    const rows = dataResult.map(processRow)

    db.close()

    return {
      columns,
      rows,
      totalRows,
      truncated: offset + rows.length < totalRows,
    }
  } catch (error) {
    db.close()
    throw error
  }
}

/**
 * Get row count from a file without reading all data
 */
export async function getDuckDBRowCount(filePath: string): Promise<number> {
  const fileType = getDuckDBFileType(filePath)
  if (!fileType) {
    throw new Error(`Unsupported file type for DuckDB parser: ${filePath}`)
  }

  const escapedPath = filePath.replace(/'/g, "''")
  const readFn = getReadFunction(fileType, escapedPath)
  const db = new duckdb.Database(":memory:")

  try {
    await installExtensions(db, fileType)

    const result = await queryDuckDB(
      db,
      `SELECT COUNT(*) as cnt FROM ${readFn}`
    )
    const count = Number(result[0]?.cnt || 0)
    db.close()
    return count
  } catch (error) {
    db.close()
    throw error
  }
}

/**
 * Get column info from a file without reading data
 */
export async function getDuckDBColumns(
  filePath: string
): Promise<ParsedColumn[]> {
  const fileType = getDuckDBFileType(filePath)
  if (!fileType) {
    throw new Error(`Unsupported file type for DuckDB parser: ${filePath}`)
  }

  const escapedPath = filePath.replace(/'/g, "''")
  const readFn = getReadFunction(fileType, escapedPath)
  const db = new duckdb.Database(":memory:")

  try {
    await installExtensions(db, fileType)

    const result = await queryDuckDB(
      db,
      `DESCRIBE SELECT * FROM ${readFn}`
    )

    const columns: ParsedColumn[] = result.map((row) => ({
      name: String(row.column_name || row.name || ""),
      type: mapDuckDBType(String(row.column_type || row.type || "")),
    }))

    db.close()
    return columns
  } catch (error) {
    db.close()
    throw error
  }
}

/**
 * Execute an arbitrary SQL query against a data file
 * The file is available as the 'data' table in the query
 */
export async function queryDataFile(
  filePath: string,
  sql: string,
  options: { sheetName?: string } = {}
): Promise<ParsedData> {
  const { sheetName } = options

  // Detect file type - support CSV in addition to DuckDB native types
  const ext = path.extname(filePath).toLowerCase()
  let readFn: string

  // Escape single quotes in file path for SQL
  const escapedPath = filePath.replace(/'/g, "''")

  // Determine the read function based on file type
  if (ext === ".csv" || ext === ".tsv") {
    readFn = `read_csv('${escapedPath}', auto_detect=true)`
  } else if (ext === ".json" || ext === ".jsonl") {
    readFn = `read_json('${escapedPath}', auto_detect=true)`
  } else {
    const fileType = getDuckDBFileType(filePath)
    if (!fileType) {
      throw new Error(`Unsupported file type for SQL queries: ${filePath}`)
    }
    readFn = getReadFunction(fileType, escapedPath, sheetName)
  }

  const db = new duckdb.Database(":memory:")

  try {
    // Install extensions if needed (for Excel)
    const fileType = getDuckDBFileType(filePath)
    if (fileType) {
      await installExtensions(db, fileType)
    }

    // Create a view named 'data' for the file
    await queryDuckDB(db, `CREATE VIEW data AS SELECT * FROM ${readFn}`)

    // Execute the user's SQL query
    const dataResult = await queryDuckDB(db, sql)

    if (dataResult.length === 0) {
      db.close()
      return {
        columns: [],
        rows: [],
        totalRows: 0,
        truncated: false,
      }
    }

    // Infer columns from the first row
    const columns: ParsedColumn[] = Object.keys(dataResult[0]).map((name) => {
      const value = dataResult[0][name]
      let colType: ColumnType = "string"
      if (typeof value === "number") colType = "number"
      else if (typeof value === "boolean") colType = "boolean"
      else if (value instanceof Date) colType = "date"
      return { name, type: colType }
    })

    const rows = dataResult.map(processRow)

    db.close()

    return {
      columns,
      rows,
      totalRows: rows.length,
      truncated: false,
    }
  } catch (error) {
    db.close()
    throw error
  }
}

/**
 * Parse an xlsx file (which is a ZIP archive) and extract sheet names from xl/workbook.xml
 * This is a pure Node.js implementation without additional dependencies.
 */
async function extractSheetNamesFromXlsx(filePath: string): Promise<string[]> {
  // Read the file as a buffer
  const buffer = await readFile(filePath)

  // XLSX files are ZIP archives. We need to find and read xl/workbook.xml
  // ZIP file structure: local file headers followed by file data

  const sheets: string[] = []
  let offset = 0

  while (offset < buffer.length - 4) {
    // Check for local file header signature (0x04034b50)
    const signature = buffer.readUInt32LE(offset)
    if (signature !== 0x04034b50) break

    // Parse local file header
    const compressionMethod = buffer.readUInt16LE(offset + 8)
    const compressedSize = buffer.readUInt32LE(offset + 18)
    const uncompressedSize = buffer.readUInt32LE(offset + 22)
    const fileNameLength = buffer.readUInt16LE(offset + 26)
    const extraFieldLength = buffer.readUInt16LE(offset + 28)

    const fileName = buffer.toString('utf8', offset + 30, offset + 30 + fileNameLength)
    const dataStart = offset + 30 + fileNameLength + extraFieldLength
    const dataEnd = dataStart + compressedSize

    // Look for xl/workbook.xml
    if (fileName === 'xl/workbook.xml') {
      let xmlContent: string

      if (compressionMethod === 0) {
        // No compression (stored)
        xmlContent = buffer.toString('utf8', dataStart, dataEnd)
      } else if (compressionMethod === 8) {
        // Deflate compression
        const compressedData = buffer.subarray(dataStart, dataEnd)
        try {
          // Use zlib.inflateRaw for raw deflate data
          const decompressed = await new Promise<Buffer>((resolve, reject) => {
            const inflate = createInflateRaw()
            const chunks: Buffer[] = []
            inflate.on('data', (chunk: Buffer) => chunks.push(chunk))
            inflate.on('end', () => resolve(Buffer.concat(chunks)))
            inflate.on('error', reject)
            inflate.end(compressedData)
          })
          xmlContent = decompressed.toString('utf8')
        } catch (err) {
          console.warn('[duckdb-parser] Failed to decompress workbook.xml:', err)
          break
        }
      } else {
        console.warn(`[duckdb-parser] Unsupported compression method: ${compressionMethod}`)
        break
      }

      // Parse sheet names from XML
      // Looking for: <sheet name="SheetName" ... /> or <sheet ... name="SheetName" .../>
      // The name attribute can appear anywhere in the tag
      // Try multiple regex patterns to be more robust
      const sheetTagRegex = /<sheet\s+[^>]*>/gi
      let tagMatch
      while ((tagMatch = sheetTagRegex.exec(xmlContent)) !== null) {
        const tag = tagMatch[0]
        // Extract name attribute from the tag
        const nameMatch = /name=["']([^"']+)["']/i.exec(tag)
        if (nameMatch && nameMatch[1]) {
          sheets.push(nameMatch[1])
        }
      }

      // Debug log
      console.log('[duckdb-parser] Found sheets in workbook.xml:', sheets)

      break // Found workbook.xml, no need to continue
    }

    // Move to next file in the archive
    offset = dataEnd
  }

  return sheets
}

/**
 * List sheets in an Excel file
 * Supports both .xlsx (modern Excel) and provides meaningful error for .xls (legacy)
 */
export async function listExcelSheets(filePath: string): Promise<string[]> {
  const ext = path.extname(filePath).toLowerCase()

  // Check if it's a legacy .xls file (not supported by DuckDB)
  if (ext === '.xls') {
    console.warn('[duckdb-parser] .xls format is not supported. Only .xlsx files are supported.')
    // Return empty array - the UI should show an appropriate message
    return []
  }

  try {
    // Extract sheet names directly from the xlsx file
    const sheets = await extractSheetNamesFromXlsx(filePath)

    if (sheets.length === 0) {
      console.warn('[duckdb-parser] No sheets found in Excel file')
      return []
    }

    return sheets
  } catch (error) {
    console.warn('[duckdb-parser] Failed to list Excel sheets:', error)
    return []
  }
}
